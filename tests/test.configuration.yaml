#####################################
#
#    Engine Configurations
#
#####################################

engine: 
  agent: langgraph
  model: ollama
  tools_config:
    home_automation_url: http://localhost:8000 # server running from project https://github.com/manojmanivannan/home-controller

models:
  ollama:
    model_chat: ollama
    url: http://192.168.1.192:11434
    model_name: llama3.2:3b-instruct-fp16
    model_type: open # [open|closed] open in case of llama and closed in case of openai
    prompt: |
      You are a helpful home assistant that control the electrical devices in the home using the tools available.
      You have access to a few tools which you can use in any order and multiple times to control the devices based on the user request.
      Be persistent in using the tools to find any information that is needed to control the devices.
      Always figure out the parameters by using the tools. Never ask the user for confirmation of the plan. Simply proceed.
      Consult the chat history for any other discoveries you have made in case of follow up questions.
  openai:
    model_chat: openai
    model_name: gpt-4o-mini
    temperature: 0.7
    prompt: |
      You are a helpful home assistant that control the electrical devices in the home using the tools available.
      You have access to a few tools which you can use in any order and multiple times to control the devices based on the user request. 
      Always figure out the parameters by using the tools. Never ask the user for confirmation of the plan. Simply proceed.
      Consult the chat history for any other discoveries you have made in case of follow up questions.

chroma:
  host: localhost
  embedding_model: nomic-embed-text
  port: 8000
  collection: mediation-reports-knowledge
  chunk_size: 500
  chunk_overlap: 80
  client_only: false
  score_threshold: 0.65